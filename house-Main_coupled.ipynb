{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm, gamma, poisson\n",
    "import operator\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 12,  4],\n",
       "       [11, 17,  4],\n",
       "       [ 0, 21,  4],\n",
       "       [ 0,  0,  5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeattleA = np.array([[15,12,4],[11,17,4],[0,21,4],[0,0,5]])\n",
    "SeattleA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(DATA):\n",
    "    hsA = np.sum(DATA,axis=0)\n",
    "    isA = np.sum(DATA,axis=1)\n",
    "    colA = np.array(range(1,len(hsA)+1))\n",
    "    rowA = np.array(range(0,len(hsA)+1))\n",
    "    \n",
    "    xA = np.sum(isA*rowA) # Final size\n",
    "    N = np.sum(hsA*colA) # Population size\n",
    "    \n",
    "    return {'hsA' : hsA, 'isA' : isA, 'colA' : colA, 'rowA' : rowA, 'xA' : xA, 'N' : N}\n",
    "\n",
    "def PCOUP(Xdata, epss, k, run):\n",
    "    \"\"\"Partially coupled ABC algorithm to obtain run accepted values.\"\"\"\n",
    "     #initialize empty zero array\n",
    "    output = np.zeros(((2*epss[1]+1)*run, 5), dtype = float)\n",
    "    simcount=0\n",
    "    count=0\n",
    "    jj=0\n",
    "    \n",
    "    while jj<run:\n",
    "        simcount+=1\n",
    "        lambda_L = np.random.exponential(1,1) # Sample lambda_L\n",
    "        J = House_COUP(Xdata,epss[1],lambda_L,k) # Run coupled simulations\n",
    "        W = J[J[:,3]<J[:,4],:]        # W contains successful simulations (infect close to xA individuals)\n",
    "        if W.size == 5:\n",
    "            W = np.array(W).reshape((-1, 5))\n",
    "        if W[:,0].size > 0:\n",
    "            if min(W[:, 1])<=epss[0]:\n",
    "                jj+=1\n",
    "                for ii in range(W[:, 0].size):\n",
    "                    if W[ii, 1]<=epss[0]:\n",
    "                        count+=1\n",
    "                        output[count-1,:]=np.r_[W[ii,1:4],lambda_L]\n",
    "                        \n",
    "    # Stores values from simulation - these include closeness of simulated epidemic \n",
    "    # to data, range of lambda_G values and lambda_L\n",
    "    return {'OUTPUT':output[0:count,:], 'simcount':simcount}\n",
    "\n",
    "\n",
    "def House_COUP(Xdata,epsil,lambda_L,k):\n",
    "    \"\"\"Partially coupled ABC algorithm for household epidemics\n",
    "    lambda_L is drawn from the prior (or however)\n",
    "    Code finds lambda_G values consistent with the data\n",
    "    Input: Xdata - Epidemic data to compare simulations with.\n",
    "    epsil - Max distance between simulated and observed final size for a simulation \n",
    "    to be accepted. (Tighter control on distance after simulations straightforward).\n",
    "    lambda_L - local infection (household) rate\n",
    "    k - Gamma(k,k) infectious period with k=0 a constant infectious period.\"\"\"\n",
    "    hsA = np.sum(Xdata, axis = 0) # hsA[i] - Number of households of size i\n",
    "    isA = np.sum(Xdata, axis = 1) # isA[i] - Number of households with i-1 infectives\n",
    "    colA = np.arange(1, hsA.shape[0]+1)\n",
    "    rowA = np.arange(0, hsA.shape[0]+1)\n",
    "    \n",
    "    xA = np.sum(isA*rowA) # Final size\n",
    "    HH = hsA.shape[0] # HH maximum household size\n",
    "    ks = np.arange(1, HH+1)\n",
    "    \n",
    "    n = np.repeat(ks, hsA, axis=0)\n",
    "    m = n.shape[0]# Number of households\n",
    "    N = np.sum(n) # Population size\n",
    "    NS = N # Number of susceptibles\n",
    "    sev=0       # Running tally of severity (sum of infectious periods)\n",
    "    threshold=0 # Running tally of (global) threshold required for the next infection\n",
    "    \n",
    "    ni = np.repeat(0, n.shape[0], axis = 0) # infectives (per household)\n",
    "    ns = n.copy() # susceptibles (per household)\n",
    "    \n",
    "    OUT = np.zeros((HH+1, HH))\n",
    "    OUT[0, :] = hsA # Epidemic data in the same form as Xdata\n",
    "                   # Start with everybody susceptible\n",
    "    \n",
    "    DISS = np.zeros((2*epsil+1, 5)) # Matrix for collecting epidemics infecting within epsil of xA infectives.\n",
    "    SEVI = np.zeros((N, 3)) # Matrix to keep track of number of infectives, severity and threshold.\n",
    "    ys=0    # number of infectives\n",
    "    count=0 # number of global infections taking place. First global infection is the introductory case. \n",
    "    \n",
    "    while ys<=(xA+epsil):\n",
    "        # Only need to consider the epidemic until xA+epsil infections occur.\n",
    "        # We simulate successive global infections (should they occur) with associated\n",
    "        # local (within household epidemics)\n",
    "        # For the count+1 global infection to take place, we require that \n",
    "        # for k=1,2,..., count;  lambda_G * severity from first k infectives is larger\n",
    "        # than the k^th threshold\n",
    "        count+=1\n",
    "        kk = np.random.choice(m, 1, p = ns/ns.sum(), replace = True)[0]\n",
    "        OUT[ni[kk-1],n[kk-1]-1]=OUT[ni[kk-1],n[kk-1]-1]-1\n",
    "        hou_epi=House_epi(ns[kk-1],k,lambda_L)# Simulate a household epidemic among the remaining susceptibles in the household\n",
    "        \n",
    "        ns[kk-1]-=hou_epi[0]\n",
    "        ni[kk-1] = n[kk-1] - ns[kk-1]#update household kk data (susceptibles and infectives)\n",
    "        \n",
    "        OUT[ni[kk-1],n[kk-1]-1]+=1# Update the state of the population following the global \n",
    "        #infection and resulting household epidemic\n",
    "        NS = ns.sum()\n",
    "        threshold+=np.random.exponential(size = 1, scale = (N/NS))\n",
    "        \n",
    "        ys+=hou_epi[0]\n",
    "        sev+=hou_epi[1]\n",
    "        SEVI[count-1,:] = [ys,sev,threshold]\n",
    "        # If the number infected is close to xA, we check what value of lambda_G \n",
    "        # would be needed for an epidemic of the desired size. \n",
    "        # Note that in many cases no value of lambda_G will result in an epidemic \n",
    "        # close to xA. \n",
    "        if abs(ys-xA)<=epsil:\n",
    "            dist = np.sum(abs(OUT-Xdata))\n",
    "            TT = SEVI[0:count, 2]/SEVI[0:count, 1] #ratio of threshold to severity\n",
    "            Tlow = max(TT[0:count])\n",
    "            Thi=TT[0:count].max()   #  Thi is the maximum lambda_G which leads to at most count global infections\n",
    "            DISS[(ys-(xA-epsil)).astype('int'), :] = [1,dist,abs(ys-xA),Tlow,Thi]\n",
    "            \n",
    "    return DISS\n",
    "\n",
    "\n",
    "def House_epi(n,k,lambda_L):\n",
    "    \n",
    "    i=0\n",
    "    sev=0\n",
    "    \n",
    "    if n == 1:\n",
    "        i = 1\n",
    "        if k == 0:\n",
    "            sev = 1\n",
    "        if k > 0:\n",
    "            sev = np.random.gamma(k, 1/k, 1)\n",
    "    \n",
    "    if n > 1:\n",
    "        t = thresH(n)\n",
    "        if k == 0:\n",
    "            q = np.repeat(1.0,n)\n",
    "        if k > 0:\n",
    "            q = np.random.gamma(size=n, shape=k, scale=1/k)\n",
    "        t = np.append(t, 2*lambda_L*np.sum(q))\n",
    "        \n",
    "        i = 0\n",
    "        test = 0\n",
    "        while test == 0:\n",
    "            i += 1\n",
    "            if t[i-1] > (lambda_L*np.sum(q[0:i])):\n",
    "                test = 1 \n",
    "                sev = np.sum(q[0:i])\n",
    "                \n",
    "    return np.array([i,sev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 177 is out of bounds for axis 0 with size 177",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-37a382e3c1cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mOUTP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCOUP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mOUT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OUTPUT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mOUTP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'simcount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-294-08110c0ee956>\u001b[0m in \u001b[0;36mPCOUP\u001b[0;34m(Xdata, epss, k, run)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msimcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlambda_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Sample lambda_L\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHouse_COUP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_L\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Run coupled simulations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m# W contains successful simulations (infect close to xA individuals)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-294-08110c0ee956>\u001b[0m in \u001b[0;36mHouse_COUP\u001b[0;34m(Xdata, epsil, lambda_L, k)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mhou_epi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0msev\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mhou_epi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mSEVI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m# If the number infected is close to xA, we check what value of lambda_G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# would be needed for an epidemic of the desired size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 177 is out of bounds for axis 0 with size 177"
     ]
    }
   ],
   "source": [
    "DATA=SeattleA\n",
    "\n",
    "# Main code for partially coupled ABC for household epidemics\n",
    "tstartC = time.time()\n",
    "\n",
    "# Process data\n",
    "proc = process(DATA)\n",
    "hsA = proc['hsA']\n",
    "isA = proc['isA']\n",
    "colA = proc['colA']\n",
    "rowA = proc['rowA']\n",
    "xA = proc['xA']\n",
    "N = proc['N']\n",
    "\n",
    "# Set precision thresholds (epss), infectious period (k) and\n",
    "# number of iterations (run)\n",
    "epss = np.array((8,1))\n",
    "k = 0\n",
    "run = 10\n",
    "\n",
    "OUTP = PCOUP(DATA,epss,k,run)\n",
    "OUT=OUTP['OUTPUT']\n",
    "OUTP['simcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-aa92c01c6d15>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-aa92c01c6d15>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    OUT=OUTP$OUTPUT\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Main code for partially coupled ABC for household epidemics\n",
    "#\n",
    "#\n",
    "\n",
    "tstartC=proc.time()\n",
    "\n",
    "#\n",
    "# Set dataset: SeattleA, SeattleB, Tecumseh1, Tecumseh2\n",
    "#\n",
    "\n",
    "data(SeattleA)\n",
    "DATA=SeattleA\n",
    "\n",
    "#\n",
    "# Process data\n",
    "#\n",
    "\n",
    "proc = process(DATA)\n",
    "hsA = proc[[1]]; isA = proc[[2]]; colA = proc[[3]]; rowA = proc[[4]]; xA = proc[[5]]; N = proc[[6]]\n",
    "\n",
    "#\n",
    "# Set precision thresholds (epss), infectious period (k) and\n",
    "# number of iterations (run)\n",
    "#\n",
    "\n",
    "epss=c(8,1)\n",
    "k=0\n",
    "run=1000\n",
    "\n",
    "OUTP=PCOUP(DATA,epss,k,run)\n",
    "OUT=OUTP$OUTPUT\n",
    "OUTP$simcount\n",
    "\n",
    "#\n",
    "# Compute posterior means and standard deviations for partially coupled ABC\n",
    "#\n",
    "\n",
    "wei=0\n",
    "moMG=rep(0,2)\n",
    "moML=rep(0,2)\n",
    "\n",
    "Count=length(OUT[,1])\n",
    "# Number of stored values - note there might be one for each accepted simulation\n",
    "\n",
    "for(i in 1:Count)\n",
    "{\n",
    "wei=wei+Mexp(0,1,0,OUT[i,3],OUT[i,4])\n",
    "for(j in 1:2)\n",
    "{\n",
    "moMG[j]=moMG[j]+Mexp(j,1,0,OUT[i,3],OUT[i,4])\n",
    "moML[j]=moML[j]+Mexp(0,1,0,OUT[i,3],OUT[i,4])*OUT[i,5]^j\n",
    "}\n",
    "}\n",
    "\n",
    "meanG=moMG[1]/wei\n",
    "sdG=sqrt(moMG[2]/wei-meanG^2)\n",
    "meanL=moML[1]/wei\n",
    "sdL=sqrt(moML[2]/wei-meanL^2)\n",
    "\n",
    "#\n",
    "# Computes transformed means and standard deviations of\n",
    "# q_G = exp(-lambdaG * xA/N); q_L = exp(-lambdaL)\n",
    "#\n",
    "\n",
    "A1=1+xA/N\n",
    "A2=1+2*xA/N\n",
    "\n",
    "WEIq=exp(-OUT[,3])-exp(-OUT[,4])\n",
    "moqG=sum(exp(-A1*OUT[,3])-exp(-A1*OUT[,4]))/A1\n",
    "moqG[2]=sum(exp(-A2*OUT[,3])-exp(-A2*OUT[,4]))/A2\n",
    "\n",
    "moqL=sum(WEIq*exp(-OUT[,5]))\n",
    "moqL[2]=sum(WEIq*exp(-2*OUT[,5]))\n",
    "\n",
    "meanqG=moqG[1]/wei\n",
    "sdqG=sqrt(moqG[2]/wei-meanqG^2)\n",
    "meanqL=moqL[1]/wei\n",
    "sdqL=sqrt(moqL[2]/wei-meanqL^2)\n",
    "\n",
    "#\n",
    "# Summarise results\n",
    "#\n",
    "\n",
    "# Parameter means and sd\n",
    "c(meanG,sdG,meanL,sdL)\n",
    "\n",
    "# Transformed parameters means and sd (compare with Clancy and O'Neill (2008)\n",
    "# and Neal (2012))\n",
    "c(meanqG,sdqG,meanqL,sdqL)\n",
    "\n",
    "# Time taken.\n",
    "\n",
    "tendC=proc.time()\n",
    "tendC-tstartC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
